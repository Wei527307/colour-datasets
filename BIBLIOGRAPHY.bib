@phdthesis{Asano2015,
  author       = {Asano, Yuta},
  school       = {R.I.T.},
  title        = {{Individual Colorimetric Observers for Personalized
    Color Imaging}},
  year         = 2015,
}
@article{Breneman1987b,
  abstract     = {While each of his or her two eyes was independently
    adapted to a different illuminant in viewing a complex visual
    field, each of a number of observers matched a series of test
    colors seen by one eye with a juxtaposed variable stimulus seen by
    the other eye. The 2 degrees test and matching stimuli were
    located centrally in the complex adapting field, which subtended
    an angle of 31 degrees X 24 degrees. In making the matches, the
    observer viewed the test and matching stimuli for a series of
    brief intervals (approximately 1 sec) while viewing the complex
    adapting field with normal eye movements. Nine experiments were
    performed with different pairs of illuminants and different
    illuminances ranging from that of an average living room to that
    of a scene illuminated with hazy sunlight. In three other
    experiments each of the observer's two eyes was adapted to a
    different illuminance of D55. The amount of adaptation was more
    nearly complete at high levels of illuminance than at low levels,
    and the proportional amount of adaptation was less for the "blue"
    receptors. When adaptation coefficients were determined from the
    actual adaptation differences (e.g., from corresponding
    tristimulus values for matching neutrals) rather than from the
    adapting illuminants, a linear von Kries transformation based on
    experimentally determined visual primaries gave corresponding
    chromaticities that were in good agreement with the results
    obtained in each of the chromatic-adaptation experiments, except
    at the lowest illuminances. The results of the experiments in
    which each eye was adapted to different levels of the same
    illuminant indicated again that adaptation to the different levels
    was incomplete, the proportional amount of adaptation being less
    at low illuminances and for the "blue" receptors. This caused a
    change in chromatic adaptation with the level of illuminance even
    when the chromaticities of the adapting lights were equal. The
    results of these experiments also indicated that higher purities
    are needed in order to produce the same absolute color appearances
    at low levels of illuminance.},
  author       = {Breneman, Edwin J.},
  doi          = {10.1364/JOSAA.4.001115},
  issn         = {1084-7529},
  journal      = {Journal of the Optical Society of America A},
  month        = jun,
  number       = 6,
  pages        = 1115,
  pmid         = 3598755,
  title        = {{Corresponding chromaticities for different states
    of adaptation to complex visual fields}},
  url          = {https://www.osapublishing.org/abstract.cfm?URI=josaa-4-6-1115
    http://www.opticsinfobase.org/josaa/fulltext.cfm?uri=josaa-4-6-1115\&id=2783},
  volume       = 4,
  year         = 1987,
}
@misc{Dyer2017,
  author       = {Dyer, Scott and Forsythe, Alexander and Irons,
    Jonathon and Mansencal, Thomas and Zhu, Miaoqi},
  title        = {{RAW to ACES Utility Data}},
  year         = 2017,
}
@inproceedings{Ebner1998,
  author       = {Ebner, Fritz and Fairchild, Mark D.},
  booktitle    = {Proc. SPIE 3300, Color Imaging: Device-Independent
    Color, Color Hardcopy, and Graphic Arts III, (2 January 1998)},
  doi          = {10.1117/12.298269},
  editor       = {Beretta, Giordano B. and Eschbach, Reiner},
  month        = jan,
  pages        = {107--117},
  title        = {{Finding constant hue surfaces in color space}},
  url          = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=936964},
  year         = 1998,
}
@misc{Haanpalo,
  author       = {Haanpalo, Jouni and {University of Kuopio}},
  doi          = {10.5281/zenodo.3269916},
  title        = {{Munsell Colors Glossy (Spectrofotometer Measured)}},
  url          = {http://www.uef.fi/web/spectral/munsell-colors-glossy-spectrofotometer-measured},
}
@misc{Haanpaloa,
  author       = {Haanpalo, Jouni and {University of Kuopio}},
  doi          = {10.5281/zenodo.3269922},
  title        = {{Paper Spectra}},
  url          = {http://www.uef.fi/web/spectral/paper-spectra},
}
@misc{Hauta-Kasari,
  author       = {Hauta-Kasari, Markku and {University of Kuopio}},
  doi          = {10.5281/zenodo.3269912},
  title        = {{Munsell Colors Matt (Spectrofotometer Measured)}},
  url          = {http://www.uef.fi/web/spectral/munsell-colors-matt-spectrofotometer-measured},
}
@misc{Hauta-Kasaria,
  author       = {Hauta-Kasari, Markku and {University of Kuopio}},
  doi          = {10.5281/zenodo.3269914},
  title        = {{Munsell Colors Matt (AOTF Measured)}},
  url          = {http://www.uef.fi/web/spectral/munsell-colors-matt-aotf-measured-},
}
@misc{Hiltunen,
  author       = {Hiltunen, Jouni and {University of Kuopio}},
  doi          = {10.5281/zenodo.3269924},
  title        = {{Lumber Spectra}},
  url          = {http://www.uef.fi/web/spectral/lumber-spectra},
}
@article{Hung1995,
  author       = {Hung, Po-Chieh and Berns, Roy S.},
  doi          = {10.1002/col.5080200506},
  issn         = 03612317,
  journal      = {Color Research \& Application},
  keywords     = {color appearance spaces,experiments to evaluate
    color space hue linearity,perceived hue},
  month        = oct,
  number       = 5,
  pages        = {285--295},
  title        = {{Determination of constant Hue Loci for a CRT gamut
    and their predictions using color appearance spaces}},
  url          = {http://doi.wiley.com/10.1002/col.5080200506},
  volume       = 20,
  year         = 1995,
}
@inproceedings{Jiang2013,
  abstract     = {Camera spectral sensitivity functions relate scene
    radiance with captured RGB triplets. They are important for many
    computer vision tasks that use color information, such as
    multispectral imaging, color rendering, and color constancy. In
    this paper, we aim to explore the space of spectral sensitivity
    functions for digital color cameras. After collecting a database
    of 28 cameras covering a variety of types, we find this space
    convex and two-dimensional. Based on this statistical model, we
    propose two methods to recover camera spectral sensitivities using
    regular reflective color targets (e.g., color checker) from a
    single image with and without knowing the illumination. We show
    the proposed model is more accurate and robust for estimating
    camera spectral sensitivities than other basis functions. We also
    show two applications for the recovery of camera spectral
    sensitivities - simulation of color rendering for cameras and
    computational color constancy.},
  author       = {Jiang, Jun and Liu, Dengyu and Gu, Jinwei and
    Susstrunk, Sabine},
  booktitle    = {2013 IEEE Workshop on Applications of Computer
    Vision (WACV)},
  doi          = {10.1109/WACV.2013.6475015},
  isbn         = {978-1-4673-5054-9},
  issn         = 21583978,
  month        = jan,
  pages        = {168--179},
  publisher    = {IEEE},
  title        = {{What is the space of spectral sensitivity functions
    for digital color cameras?}},
  url          = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6475015},
  year         = 2013,
}
@misc{Labsphere2019,
  author       = {Labsphere},
  doi          = {10.5281/zenodo.3245875},
  title        = {{Labsphere SRS-99-020}},
  year         = 2019,
}
@article{Luo1991,
  abstract     = {The experimental data from this study supplements
    the LUTCHI Colour Appearance Data as described in Part I of this
    paper. Two further experiments were carried out: one was to check
    conflicting results found previously, and another was to extend
    the range of luminance conditions used earlier. In addition, a
    brightness attribute was added to the original lightness,
    colourfulness, and hue scales for colour assessment. Experiment I
    results verified the uncertainties found previously in the
    comparison between luminous and nonluminous colours, and between
    the grey background results with and without a white border.
    Experiment II results revealed the changes in four perceived
    attributes under six quite different adapting luminances. The
    results were then used to test five uniform colour spaces and
    colour-appearance models used in Part II of this paper. Hunt's 91
    model gave more accurate predictions of the experimental visual
    results, in comparison with the other spaces and models. Its
    predictive error for all attributes studied is within the accuracy
    of the typical observer.},
  author       = {Luo, M. Ronnier and Clarke, Anthony A. and Rhodes,
    Peter A. and Schappo, Andr{\'{e}} and Scrivener, Stephen A. R. and
    Tait, Chris J.},
  doi          = {10.1002/col.5080160307},
  issn         = 03612317,
  journal      = {Color Research \& Application},
  month        = jun,
  number       = 3,
  pages        = {166--180},
  title        = {{Quantifying colour appearance. Part I. Lutchi
    colour appearance data}},
  url          = {http://doi.wiley.com/10.1002/col.5080160307},
  volume       = 16,
  year         = 1991,
}
@article{Luo1991a,
  abstract     = {The acquisition of the LUTCHI Colour Appearance Data
    has been described in Part I of this article. Having obtained the
    data, they were used to test the accuracy of prediction for
    various colour spaces and models. The results clearly indicate
    that Hunt's 91 model gives the best fit to the visual results of
    all the models studied. Hunt's 91 has been further refined to
    improve the fit to the colourfulness results, and this refined
    model has been designated Hunt-ACAM (ACAM being the Alvey Colour
    Appearance Model). The error of prediction from Hunt-ACAM is close
    to the typical error that is seen to occur between individuals'
    results and the mean visual results. This performance is
    considered to be very satisfactory, and the model is therefore
    believed to provide a reasonably accurate way of evaluating colour
    fidelity for various colour reproduction systems. Various
    chromatic-adaptation transformations were also compared with three
    sets of corresponding chromaticities derived from the results of
    experiments conducted under four conditions of chromatic
    adaptation. The results are in reasonable agreement with those
    obtained by Helson et al. [Illum. Eng. 47, 221-233 (1952)] and Lam
    and Rigg [Ph.D. thesis, University of Bradford (1985)]. All
    results indicate that the Bradford and Hunt-ACAM transformations
    perform the best and the second best, respectively, of all the
    selected formulae. The current CIE recommendation does not perform
    as well as expected.},
  author       = {Luo, M. Ronnier and Clarke, Anthony A. and Rhodes,
    Peter A. and Schappo, Andr{\'{e}} and Scrivener, Stephen A.R. and
    Tait, Chris J.},
  doi          = {10.1002/col.5080160308},
  issn         = 15206378,
  journal      = {Color Research \& Application},
  number       = 3,
  pages        = {181--197},
  title        = {{Quantifying colour appearance. Part II. Testing
    colour models performance using lutchi colour appearance data}},
  volume       = 16,
  year         = 1991,
}
@article{Luo1993,
  abstract     = {The experimental data from this study supplements
    the LUTCHI Colour Appearance Data as described in Part I of this
    paper. Two further experiments were carried out: one was to check
    conflicting results found previously, and another was to extend
    the range of luminance conditions used earlier. In addition, a
    brightness attribute was added to the original lightness,
    colourfulness, and hue scales for colour assessment. Experiment I
    results verified the uncertainties found previously in the
    comparison between luminous and nonluminous colours, and between
    the grey background results with and without a white border.
    Experiment II results revealed the changes in four perceived
    attributes under six quite different adapting luminances. The
    results were then used to test five uniform colour spaces and
    colour‐appearance models used in Part II of this paper. Hunt's 91
    model gave more accurate predictions of the experimental visual
    results, in comparison with the other spaces and models. Its
    predictive error for all attributes studied is within the accuracy
    of the typical observer. Copyright {\textcopyright} 1993 Wiley
    Periodicals, Inc., A Wiley Company},
  author       = {Luo, M. Ronnier and Gao, X. Wang and Rhodes, Peter
    A. and Xin, H. John and Clarke, Anthony A. and Scrivener, Stephen
    A.R.},
  doi          = {10.1002/col.5080180207},
  issn         = 15206378,
  journal      = {Color Research \& Application},
  number       = 2,
  pages        = {98--113},
  title        = {{Quantifying colour appearance. part III.
    Supplementary LUTCHI colour appearance data}},
  volume       = 18,
  year         = 1993,
}
@article{Luo1999,
  abstract     = {Predicting the binding mode of flexible polypeptides
    to proteins is an important task that falls outside the domain of
    applicability of most small molecule and protein−protein docking
    tools. Here, we test the small molecule flexible ligand docking
    program Glide on a set of 19 non-$\alpha$-helical peptides and
    systematically improve pose prediction accuracy by enhancing Glide
    sampling for flexible polypeptides. In addition, scoring of the
    poses was improved by post-processing with physics-based implicit
    solvent MM- GBSA calculations. Using the best RMSD among the top
    10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA}
    for the interface backbone atoms) increased from 21% with default
    Glide SP settings to 58% with the enhanced peptide sampling and
    scoring protocol in the case of redocking to the native protein
    structure. This approaches the accuracy of the recently developed
    Rosetta FlexPepDock method (63% success for these 19 peptides)
    while being over 100 times faster. Cross-docking was performed for
    a subset of cases where an unbound receptor structure was
    available, and in that case, 40% of peptides were docked
    successfully. We analyze the results and find that the optimized
    polypeptide protocol is most accurate for extended peptides of
    limited size and number of formal charges, defining a domain of
    applicability for this approach.},
  author       = {Luo, M. Ronnier and Rhodes, Peter A.},
  doi          = {10.1002/(SICI)1520-6378(199908)24:4<295::AID-COL10>3.0.CO;2-K},
  issn         = {0361-2317},
  journal      = {Color Research \& Application},
  month        = aug,
  number       = 4,
  pages        = {295--296},
  title        = {{Corresponding-colour datasets}},
  url          = {http://doi.wiley.com/10.1002/%28SICI%291520-6378%28199908%2924%3A4%3C295%3A%3AAID-COL10%3E3.0.CO%3B2-K},
  volume       = 24,
  year         = 1999,
}
@misc{Marszalec,
  author       = {Marszalec, Elzbieta and {University of Kuopio}},
  doi          = {10.5281/zenodo.3269926},
  title        = {{Agfa IT8.7/2 Set}},
  url          = {http://www.uef.fi/web/spectral/agfa-it8.7/2-set},
}
@misc{OpenpyxlDevelopers2019,
  author       = {{Openpyxl Developers}},
  title        = {openpyxl},
  url          = {https://bitbucket.org/openpyxl/openpyxl/},
  year         = 2019,
}
@misc{Orava,
  author       = {Orava, Joni and {University of Kuopio}},
  doi          = {10.5281/zenodo.3269918},
  title        = {{Munsell Colors Glossy (All) (Spectrofotometer
    Measured)}},
  url          = {http://www.uef.fi/web/spectral/munsell-colors-glossy-all-spectrofotometer-measured},
}
@misc{Silvennoinen,
  author       = {Silvennoinen, Raimo and {University of Kuopio}},
  doi          = {10.5281/zenodo.3269920},
  title        = {{Forest Colors}},
  url          = {http://www.uef.fi/web/spectral/forest-colors},
}
@misc{X-Rite2016,
  author       = {X-Rite},
  title        = {{New Color Specifications for ColorChecker SG and
    Classic Charts}},
  url          = {https://xritephoto.com/ph_product_overview.aspx?ID=938\&Action=Support\&SupportID=5884},
  urldate      = {2019-06-14},
  year         = 2016,
}
